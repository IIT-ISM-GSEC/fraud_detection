{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiXo2ON33ymV",
        "outputId": "8f3f1213-aa9d-4749-fc16-521c96c43c26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==2.7 in c:\\users\\acer\\anaconda3\\lib\\site-packages (2.7.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow==2.7) (3.3.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow==2.7) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow==2.7) (1.22.1)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow==2.7) (2.7.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow==2.7) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow==2.7) (2.7.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow==2.7) (0.23.1)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow==2.7) (1.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow==2.7) (0.37.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow==2.7) (3.7.4.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow==2.7) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow==2.7) (1.12)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow==2.7) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow==2.7) (3.19.3)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow==2.7) (1.0.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow==2.7) (2.7.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow==2.7) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow==2.7) (1.12.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow==2.7) (1.34.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow==2.7) (1.1.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow==2.7) (12.0.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow==2.7) (58.0.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow==2.7) (2.26.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow==2.7) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow==2.7) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow==2.7) (2.0.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow==2.7) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow==2.7) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow==2.7) (2.3.3)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.7) (4.8.1)\n",
            "Requirement already satisfied: zipp>=0.5 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.7) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7) (0.4.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7) (1.26.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7) (3.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7) (3.1.1)\n"
          ]
        }
      ],
      "source": [
        "# Install tensor flow 2.7 required \n",
        "!pip install tensorflow==2.7\n",
        "import os\n",
        "from pickle import dump\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"cred.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xj8qrAwK0HLQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import os\n",
        "import numpy as np\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
        "# from tensorflow.keras import Model\n",
        "# from tensorflow.keras.models import Sequential, load_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uyUgmOFU0Ux0"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "data_path= ''\n",
        "output_dir =  ''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gg_aBYlJUaH5"
      },
      "source": [
        "Reading the training and test data for our problem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vtfKQxuh1Ut6"
      },
      "outputs": [],
      "source": [
        "\n",
        "training_data_df = pd.read_csv(data_path + 'data.csv')\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import os\n",
        "import numpy as np\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "D7GWolC9Dt5z",
        "outputId": "fcad3440-8d7c-45e8-a4f7-21042fb1cb4f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fyear</th>\n",
              "      <th>gvkey</th>\n",
              "      <th>sich</th>\n",
              "      <th>insbnk</th>\n",
              "      <th>understatement</th>\n",
              "      <th>option</th>\n",
              "      <th>p_aaer</th>\n",
              "      <th>new_p_aaer</th>\n",
              "      <th>misstate</th>\n",
              "      <th>act</th>\n",
              "      <th>...</th>\n",
              "      <th>soft_assets</th>\n",
              "      <th>ch_cs</th>\n",
              "      <th>ch_cm</th>\n",
              "      <th>ch_roa</th>\n",
              "      <th>issue</th>\n",
              "      <th>bm</th>\n",
              "      <th>dpi</th>\n",
              "      <th>reoa</th>\n",
              "      <th>EBIT</th>\n",
              "      <th>ch_fcf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1990</td>\n",
              "      <td>1009</td>\n",
              "      <td>3460.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>10.047</td>\n",
              "      <td>...</td>\n",
              "      <td>0.312448</td>\n",
              "      <td>0.095082</td>\n",
              "      <td>0.082631</td>\n",
              "      <td>-0.019761</td>\n",
              "      <td>1</td>\n",
              "      <td>0.413170</td>\n",
              "      <td>0.873555</td>\n",
              "      <td>0.167620</td>\n",
              "      <td>0.161961</td>\n",
              "      <td>-0.042140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1990</td>\n",
              "      <td>1011</td>\n",
              "      <td>4841.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1.247</td>\n",
              "      <td>...</td>\n",
              "      <td>0.315904</td>\n",
              "      <td>0.188832</td>\n",
              "      <td>-0.211389</td>\n",
              "      <td>-0.117832</td>\n",
              "      <td>1</td>\n",
              "      <td>0.157887</td>\n",
              "      <td>0.745139</td>\n",
              "      <td>-0.428957</td>\n",
              "      <td>-0.157888</td>\n",
              "      <td>0.100228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1990</td>\n",
              "      <td>1017</td>\n",
              "      <td>3812.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>55.040</td>\n",
              "      <td>...</td>\n",
              "      <td>0.605342</td>\n",
              "      <td>0.097551</td>\n",
              "      <td>-0.105780</td>\n",
              "      <td>0.091206</td>\n",
              "      <td>1</td>\n",
              "      <td>2.231337</td>\n",
              "      <td>1.015131</td>\n",
              "      <td>0.394768</td>\n",
              "      <td>0.063681</td>\n",
              "      <td>0.066348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1990</td>\n",
              "      <td>1021</td>\n",
              "      <td>3861.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>24.684</td>\n",
              "      <td>...</td>\n",
              "      <td>0.793068</td>\n",
              "      <td>-0.005725</td>\n",
              "      <td>-0.249704</td>\n",
              "      <td>0.017545</td>\n",
              "      <td>1</td>\n",
              "      <td>1.043582</td>\n",
              "      <td>1.026261</td>\n",
              "      <td>0.094822</td>\n",
              "      <td>0.088347</td>\n",
              "      <td>-0.017358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1990</td>\n",
              "      <td>1028</td>\n",
              "      <td>7385.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>17.325</td>\n",
              "      <td>...</td>\n",
              "      <td>0.869182</td>\n",
              "      <td>-0.231536</td>\n",
              "      <td>-1.674893</td>\n",
              "      <td>-0.466667</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.602508</td>\n",
              "      <td>0.598443</td>\n",
              "      <td>-0.942379</td>\n",
              "      <td>-0.700821</td>\n",
              "      <td>0.130349</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 51 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   fyear  gvkey    sich  insbnk  understatement  option  p_aaer  new_p_aaer  \\\n",
              "0   1990   1009  3460.0       0               0       0     NaN         NaN   \n",
              "1   1990   1011  4841.0       0               0       0     NaN         NaN   \n",
              "2   1990   1017  3812.0       0               0       0     NaN         NaN   \n",
              "3   1990   1021  3861.0       0               0       0     NaN         NaN   \n",
              "4   1990   1028  7385.0       0               0       0     NaN         NaN   \n",
              "\n",
              "   misstate     act  ...  soft_assets     ch_cs     ch_cm    ch_roa  issue  \\\n",
              "0         0  10.047  ...     0.312448  0.095082  0.082631 -0.019761      1   \n",
              "1         0   1.247  ...     0.315904  0.188832 -0.211389 -0.117832      1   \n",
              "2         0  55.040  ...     0.605342  0.097551 -0.105780  0.091206      1   \n",
              "3         0  24.684  ...     0.793068 -0.005725 -0.249704  0.017545      1   \n",
              "4         0  17.325  ...     0.869182 -0.231536 -1.674893 -0.466667      0   \n",
              "\n",
              "         bm       dpi      reoa      EBIT    ch_fcf  \n",
              "0  0.413170  0.873555  0.167620  0.161961 -0.042140  \n",
              "1  0.157887  0.745139 -0.428957 -0.157888  0.100228  \n",
              "2  2.231337  1.015131  0.394768  0.063681  0.066348  \n",
              "3  1.043582  1.026261  0.094822  0.088347 -0.017358  \n",
              "4 -1.602508  0.598443 -0.942379 -0.700821  0.130349  \n",
              "\n",
              "[5 rows x 51 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_data_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mRZFAxQe1hh8"
      },
      "outputs": [],
      "source": [
        "scalar = MinMaxScaler(feature_range=(0,1))\n",
        "X=training_data_df.drop('misstate' ,axis=1)\n",
        "scaled_training = scalar.fit_transform(training_data_df)\n",
        "\n",
        "# scaled_test = scalar.fit_transform(test_data_df)\n",
        "\n",
        "scaled_training_df = pd.DataFrame(data = scaled_training, columns=training_data_df.columns)\n",
        "# scaled_training_df=pd.concat([scaled_training_df,training_data_df['misstate']],axis=0)\n",
        "\n",
        "dump(scalar, open('scaler.pkl', 'wb'))\n",
        "# scaled_test_df = pd.DataFrame(data = scaled_test, columns=training_data_df.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAnfWHw7UlcY"
      },
      "source": [
        "let us have a look on scaled data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "wNRwScsNE_rQ",
        "outputId": "919c172c-afca-4445-fdd7-785ff9cca8ff"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fyear</th>\n",
              "      <th>gvkey</th>\n",
              "      <th>sich</th>\n",
              "      <th>insbnk</th>\n",
              "      <th>understatement</th>\n",
              "      <th>option</th>\n",
              "      <th>misstate</th>\n",
              "      <th>act</th>\n",
              "      <th>ap</th>\n",
              "      <th>at</th>\n",
              "      <th>...</th>\n",
              "      <th>soft_assets</th>\n",
              "      <th>ch_cs</th>\n",
              "      <th>ch_cm</th>\n",
              "      <th>ch_roa</th>\n",
              "      <th>issue</th>\n",
              "      <th>bm</th>\n",
              "      <th>dpi</th>\n",
              "      <th>reoa</th>\n",
              "      <th>EBIT</th>\n",
              "      <th>ch_fcf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>0.339497</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000067</td>\n",
              "      <td>0.000094</td>\n",
              "      <td>0.000079</td>\n",
              "      <td>...</td>\n",
              "      <td>0.311332</td>\n",
              "      <td>0.409052</td>\n",
              "      <td>0.514015</td>\n",
              "      <td>0.501581</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.622087</td>\n",
              "      <td>0.185805</td>\n",
              "      <td>0.993130</td>\n",
              "      <td>0.948638</td>\n",
              "      <td>0.417252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000022</td>\n",
              "      <td>0.479034</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.000019</td>\n",
              "      <td>...</td>\n",
              "      <td>0.314826</td>\n",
              "      <td>0.414881</td>\n",
              "      <td>0.505350</td>\n",
              "      <td>0.471801</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.600763</td>\n",
              "      <td>0.152748</td>\n",
              "      <td>0.986486</td>\n",
              "      <td>0.906369</td>\n",
              "      <td>0.437468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000041</td>\n",
              "      <td>0.375063</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000362</td>\n",
              "      <td>0.000090</td>\n",
              "      <td>0.000288</td>\n",
              "      <td>...</td>\n",
              "      <td>0.607458</td>\n",
              "      <td>0.409206</td>\n",
              "      <td>0.508463</td>\n",
              "      <td>0.535277</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.773958</td>\n",
              "      <td>0.222250</td>\n",
              "      <td>0.995659</td>\n",
              "      <td>0.935650</td>\n",
              "      <td>0.432657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000054</td>\n",
              "      <td>0.380014</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000163</td>\n",
              "      <td>0.000099</td>\n",
              "      <td>0.000084</td>\n",
              "      <td>...</td>\n",
              "      <td>0.797256</td>\n",
              "      <td>0.402785</td>\n",
              "      <td>0.504221</td>\n",
              "      <td>0.512910</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.674745</td>\n",
              "      <td>0.225115</td>\n",
              "      <td>0.992319</td>\n",
              "      <td>0.938909</td>\n",
              "      <td>0.420771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000076</td>\n",
              "      <td>0.736082</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000115</td>\n",
              "      <td>0.000088</td>\n",
              "      <td>0.000067</td>\n",
              "      <td>...</td>\n",
              "      <td>0.874210</td>\n",
              "      <td>0.388746</td>\n",
              "      <td>0.462222</td>\n",
              "      <td>0.365875</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.453717</td>\n",
              "      <td>0.114986</td>\n",
              "      <td>0.980768</td>\n",
              "      <td>0.834619</td>\n",
              "      <td>0.441745</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 49 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   fyear     gvkey      sich  insbnk  understatement  option  misstate  \\\n",
              "0    0.0  0.000016  0.339497     0.0             0.0     0.0       0.0   \n",
              "1    0.0  0.000022  0.479034     0.0             0.0     0.0       0.0   \n",
              "2    0.0  0.000041  0.375063     0.0             0.0     0.0       0.0   \n",
              "3    0.0  0.000054  0.380014     0.0             0.0     0.0       0.0   \n",
              "4    0.0  0.000076  0.736082     0.0             0.0     0.0       0.0   \n",
              "\n",
              "        act        ap        at  ...  soft_assets     ch_cs     ch_cm  \\\n",
              "0  0.000067  0.000094  0.000079  ...     0.311332  0.409052  0.514015   \n",
              "1  0.000010  0.000020  0.000019  ...     0.314826  0.414881  0.505350   \n",
              "2  0.000362  0.000090  0.000288  ...     0.607458  0.409206  0.508463   \n",
              "3  0.000163  0.000099  0.000084  ...     0.797256  0.402785  0.504221   \n",
              "4  0.000115  0.000088  0.000067  ...     0.874210  0.388746  0.462222   \n",
              "\n",
              "     ch_roa  issue        bm       dpi      reoa      EBIT    ch_fcf  \n",
              "0  0.501581    1.0  0.622087  0.185805  0.993130  0.948638  0.417252  \n",
              "1  0.471801    1.0  0.600763  0.152748  0.986486  0.906369  0.437468  \n",
              "2  0.535277    1.0  0.773958  0.222250  0.995659  0.935650  0.432657  \n",
              "3  0.512910    1.0  0.674745  0.225115  0.992319  0.938909  0.420771  \n",
              "4  0.365875    0.0  0.453717  0.114986  0.980768  0.834619  0.441745  \n",
              "\n",
              "[5 rows x 49 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scaled_training_df=scaled_training_df.drop(columns=['p_aaer','new_p_aaer'])\n",
        "scaled_training_df=scaled_training_df.dropna()\n",
        "scaled_training_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0qc1ua6e2VsC"
      },
      "outputs": [],
      "source": [
        "X = scaled_training_df.drop('misstate', axis=1).values\n",
        "Y = scaled_training_df['misstate'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Rt7jbMFW3rrx"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'Sequential' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15296/842168570.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m48\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'Sequential' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.add(Dense(50, input_dim=48, activation = 'relu'))\n",
        "\n",
        "model.add(Dense(100, activation = 'relu'))\n",
        "\n",
        "model.add(Dense(50, activation = 'relu'))\n",
        "\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "model.compile(loss = 'binary_crossentropy', optimizer = 'adam')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qb3JKlCmh7aO",
        "outputId": "f1cdf57b-2c22-4d11-96d1-4824a96fb5f1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(116478, 48)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEYkrXZrVdgy",
        "outputId": "862e9c33-ba04-44bc-8990-7a258faf4b1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 50)                2450      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 100)               5100      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 50)                5050      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12,651\n",
            "Trainable params: 12,651\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "UnqSyFXR3rz-"
      },
      "outputs": [],
      "source": [
        "# X_test = scaled_test_df.drop('total_earnings', axis=1).values\n",
        "# Y_test = scaled_test_df['total_earnings'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "2OR-2Q2X_296"
      },
      "outputs": [],
      "source": [
        "# Setup for tensorboard\n",
        "from datetime import datetime\n",
        "logdir=\"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdGGyuO_3ruZ",
        "outputId": "14dcbd4f-df76-4ccd-fd3a-55955c0b1141"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "in user code:\n\n    File \"C:\\Users\\acer\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\acer\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\acer\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\acer\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 863, in train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"C:\\Users\\acer\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 537, in minimize\n        return self.apply_gradients(grads_and_vars, name=name)\n    File \"C:\\Users\\acer\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 673, in apply_gradients\n        grads_and_vars = self._aggregate_gradients(grads_and_vars)\n    File \"C:\\Users\\acer\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 489, in _aggregate_gradients\n        return self.gradient_aggregator(grads_and_vars)\n    File \"C:\\Users\\acer\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\utils.py\", line 33, in all_reduce_sum_gradients\n        if tf.__internal__.distribute.strategy_supports_no_merge_call():\n\n    AttributeError: module 'tensorflow.compat.v2.__internal__.distribute' has no attribute 'strategy_supports_no_merge_call'\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14932/3498768530.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Train the network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m training_history = model.fit(X, Y,\n\u001b[0m\u001b[0;32m      3\u001b[0m                              \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                              \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                              \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1127\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1128\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1129\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1130\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mAttributeError\u001b[0m: in user code:\n\n    File \"C:\\Users\\acer\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\acer\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\acer\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\acer\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 863, in train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"C:\\Users\\acer\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 537, in minimize\n        return self.apply_gradients(grads_and_vars, name=name)\n    File \"C:\\Users\\acer\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 673, in apply_gradients\n        grads_and_vars = self._aggregate_gradients(grads_and_vars)\n    File \"C:\\Users\\acer\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 489, in _aggregate_gradients\n        return self.gradient_aggregator(grads_and_vars)\n    File \"C:\\Users\\acer\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\utils.py\", line 33, in all_reduce_sum_gradients\n        if tf.__internal__.distribute.strategy_supports_no_merge_call():\n\n    AttributeError: module 'tensorflow.compat.v2.__internal__.distribute' has no attribute 'strategy_supports_no_merge_call'\n"
          ]
        }
      ],
      "source": [
        "training_history = model.fit(X, Y,\n",
        "                             epochs = 5,\n",
        "                             shuffle=True,\n",
        "                             verbose=0,\n",
        "                             callbacks=[tensorboard_callback])\n",
        "\n",
        "print(\"Average test loss: \", np.average(training_history.history['loss']))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4txqmr46QNF",
        "outputId": "547ae71f-7f1f-48d5-8656-f1842fcd3582"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The mean squared error for test data is 0.03634587302803993\n"
          ]
        }
      ],
      "source": [
        "test_error_rate = model.evaluate(X,\n",
        "                                 Y,\n",
        "                                 verbose=0)\n",
        "print('The mean squared error for test data is {}'.format(test_error_rate))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "7cm-WY7i7WCn"
      },
      "outputs": [],
      "source": [
        "# Read the values of features for new product and test on our traioned model \n",
        "# df_new_products = pd.read_csv(data_path + 'proposed_new_product.csv').values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "Aq3YPaMO7qm8"
      },
      "outputs": [],
      "source": [
        "# # Use our trained moel to predict\n",
        "# predictions = model.predict(df_new_products)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "eDHv9xME8M6J"
      },
      "outputs": [],
      "source": [
        "# # Scaling up the earnings prediction using our Normalisation Parameters\n",
        "# predictions = predictions + 0.1159\n",
        "# predictions = predictions/0.0000036968\n",
        "\n",
        "# print('Earnings predictions for Proposed product - ${}'.format(predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnumyE6083eI",
        "outputId": "2f8ca483-998d-48f5-bf31-e057b5ee7e47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trained Model saved at /content/drive/MyDrive/Digital_Alpha\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "model.save('trained_model.h5')\n",
        "\n",
        "print('Trained Model saved at {}'.format(output_dir))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "UYNW363T9jbn"
      },
      "outputs": [],
      "source": [
        "# Importing saved model\n",
        "\n",
        "model_trained = load_model('trained_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "DNnFV9VUJEVC"
      },
      "outputs": [],
      "source": [
        "# # Read the values of features for new product and test on our traioned model \n",
        "# df_new_products = pd.read_csv(data_path + 'proposed_new_product.csv').values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "CJ4wSGvp-BNh"
      },
      "outputs": [],
      "source": [
        "# predictions = model_trained.predict(df_new_products)\n",
        "# predictions = predictions + 0.1159\n",
        "# predictions = predictions/0.0000036968\n",
        "\n",
        "# print('Earnings predictions for Proposed product - ${}'.format(predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "FhIabCXIy3zy"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7824/1437431822.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mauth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mauth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauthenticate_user\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Gk1f3wyay6qx"
      },
      "outputs": [],
      "source": [
        "# GCP project name\n",
        "CLOUD_PROJECT = 'digital-alpha'\n",
        "BUCKET = 'gs://' + CLOUD_PROJECT + '-tf2-models'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qUl33JvzJJL",
        "outputId": "3f4d1e51-8a80-4815-ce06-fb0ec0abe217"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'gcloud' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "# Set the gcloud consol to $CLOUD_PROJECT 9Environment Variable for your Desired Project)\n",
        "!gcloud config set project $CLOUD_PROJECT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JXSBZldzI_E",
        "outputId": "f0b4f169-8915-4273-c885-85f8690af33f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gs://digital-alpha-tf2-models\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'gsutil' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "# Create the storage bucket for tf2 Models\n",
        "!gsutil mb $BUCKET\n",
        "print(BUCKET)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ocQN-r7Ft9to"
      },
      "outputs": [],
      "source": [
        "MODEL = 'fraud_prediction'\n",
        "MODEL_DIR = BUCKET + '/fraud_prediction'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypN4jJJKznNw",
        "outputId": "dda9d1c3-d18c-44d7-818b-7ca8c7c1aeae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: gs://digital-alpha-tf2-models/fraud_prediction/assets\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model.save(BUCKET + f'/{MODEL}', save_format='tf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S06k6AJDgmsO",
        "outputId": "72f12e3a-9287-4950-dfbd-64b3dfefd173"
      },
      "outputs": [],
      "source": [
        "tst=np.reshape(X[0],(1,-1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrDlb9HMgp8n",
        "outputId": "443bd82f-de7a-4a1d-c6e1-e4b97236b9aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gs://digital-alpha-tf2-models/fraud_prediction\n",
            "gs://digital-alpha-tf2-models/fraud_prediction\n"
          ]
        }
      ],
      "source": [
        "print(BUCKET + f'/{MODEL}')\n",
        "print(MODEL_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LJZ5gcsaisH",
        "outputId": "1b0767f3-d9e2-419f-c45a-32b7fc5fc581"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using endpoint [https://ml.googleapis.com/]\n",
            "Created ai platform model [projects/digital-alpha/models/fraud_prediction].\n"
          ]
        }
      ],
      "source": [
        "MODEL = 'fraud_prediction'\n",
        "!gcloud ai-platform models create $MODEL --regions=us-central1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "odfrVM4yfIpw",
        "outputId": "44bbc9b0-a95c-490f-e514-0ec08cd8fd5d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.7.0'"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "R7oJBaMVaqzF"
      },
      "outputs": [],
      "source": [
        "VERSION = 'v1'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "NpOtUHjUhS9H"
      },
      "outputs": [],
      "source": [
        "import googleapiclient.discovery\n",
        "\n",
        "def predict_json(project, model, instances, version=None):\n",
        "\n",
        "    service = googleapiclient.discovery.build('ml', 'v1')\n",
        "    name = 'projects/{}/models/{}'.format(project, model)\n",
        "\n",
        "    if version is not None:\n",
        "        name += '/versions/{}'.format(version)\n",
        "\n",
        "    response = service.projects().predict(\n",
        "        name=name,\n",
        "        body={'instances': instances}\n",
        "    ).execute()\n",
        "\n",
        "    if 'error' in response:\n",
        "        raise RuntimeError(response['error'])\n",
        "\n",
        "    return response['predictions']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXbf_TzDut6o"
      },
      "outputs": [],
      "source": [
        "\n",
        "body={'instances': tst.tolist()}\n",
        "body"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(X[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "munVP1sliM9v",
        "outputId": "6a1abcd2-5f80-4f09-9ae9-54820ff7b0b9"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'tst' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7824/857810993.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m: name 'tst' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "tst.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ibl6hJQkukq2",
        "outputId": "c1124ee7-3a7b-41e8-9272-50f7797f7f0a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'digital-alpha'"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "CLOUD_PROJECT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "B07aube1hUrd"
      },
      "outputs": [],
      "source": [
        "\n",
        "test_predictions = predict_json(CLOUD_PROJECT, 'fraud_prediction',tst.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72Sk4qgyycqT",
        "outputId": "71a45f54-cd68-453b-d697-c6ad51e30fc1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'dense_11': [0.0030233263969421387]}]"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "ukQDe0mxwzH-",
        "outputId": "9320e998-afc5-4dbf-f8d5-82d08a3e3028"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fraud_prediction\n",
            "gs://digital-alpha-tf2-models/fraud_prediction/\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'v1'"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(f'{MODEL}')\n",
        "print(MODEL_DIR)\n",
        "VERSION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_Mj9-sQbZOP",
        "outputId": "30fae288-0de4-4d25-ad5e-af8219b7f71e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;31mERROR:\u001b[0m (gcloud.ai-platform.versions.create) argument --model: Must be specified.\n",
            "Usage: gcloud ai-platform versions create VERSION --model=MODEL [optional flags]\n",
            "  optional flags may be  --accelerator | --async | --config | --description |\n",
            "                         --framework | --help | --labels | --machine-type |\n",
            "                         --max-nodes | --metric-targets | --min-nodes |\n",
            "                         --origin | --python-version | --region |\n",
            "                         --runtime-version | --staging-bucket\n",
            "\n",
            "For detailed information on this command and its flags, run:\n",
            "  gcloud ai-platform versions create --help\n"
          ]
        }
      ],
      "source": [
        "!gcloud ai-platform versions create $VERSION \\\n",
        "  --model $MODEL \\\n",
        "  --origin $MODEL_DIR \\\n",
        "  --runtime-version=2.7 \\\n",
        "  --framework='tensorflow' \\\n",
        "  --python-version=3.7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "SK1uq2zYznEX"
      },
      "outputs": [],
      "source": [
        "import googleapiclient.discovery\n",
        "\n",
        "def predict_json(project, model, instances, version=None):\n",
        "\n",
        "    service = googleapiclient.discovery.build('ml', 'v1')\n",
        "    name = 'projects/{}/models/{}'.format(project, model)\n",
        "\n",
        "    if version is not None:\n",
        "        name += '/versions/{}'.format(version)\n",
        "\n",
        "    response = service.projects().predict(\n",
        "        name=name,\n",
        "        body={'instances': instances}\n",
        "    ).execute()\n",
        "\n",
        "    if 'error' in response:\n",
        "        raise RuntimeError(response['error'])\n",
        "\n",
        "    return response['predictions']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.00000000e+00, 1.58097768e-05, 3.39496817e-01, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 6.74903384e-05, 9.36270456e-05,\n",
              "       7.88516219e-05, 8.24734092e-02, 3.96557153e-04, 9.10993969e-04,\n",
              "       2.52366826e-05, 4.43661660e-05, 2.78266706e-04, 1.47089146e-04,\n",
              "       1.96746166e-04, 2.98372978e-01, 1.07744694e-04, 1.97786456e-03,\n",
              "       2.92055222e-06, 5.86305548e-05, 1.02408503e-04, 4.84962608e-01,\n",
              "       6.51809952e-05, 1.16986875e-02, 2.69053331e-01, 8.18441340e-05,\n",
              "       4.13095538e-03, 1.66254109e-02, 5.15907137e-03, 4.88106515e-01,\n",
              "       3.78307463e-04, 1.19760479e-03, 6.64677952e-01, 5.92269115e-01,\n",
              "       5.04160006e-01, 5.20280805e-01, 3.11331659e-01, 4.09052354e-01,\n",
              "       5.14014945e-01, 5.01581288e-01, 1.00000000e+00, 6.22086777e-01,\n",
              "       1.85805232e-01, 9.93129540e-01, 9.48637756e-01, 4.17252142e-01])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "import predict as pre\n",
        "\n",
        "preds=pre.predict_fraud(X[0:10])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.0030233263969421387,\n",
              " 0.0030359625816345215,\n",
              " 0.0038477182388305664,\n",
              " 0.005808383226394653,\n",
              " 0.0028614699840545654,\n",
              " 0.005061626434326172,\n",
              " 0.0059129297733306885,\n",
              " 0.006210356950759888,\n",
              " 0.008676350116729736,\n",
              " 0.007431358098983765]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "type(preds)\n",
        "y=[]\n",
        "for dict in preds:\n",
        "    for key in list(dict.keys()):\n",
        "        y.append(dict[key][0])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cnt=0\n",
        "thresh=0.03\n",
        "for i in y:\n",
        "    if i>=thresh:\n",
        "        cnt+=1\n",
        "cnt"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of deep_learning_course_v1_guide.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
